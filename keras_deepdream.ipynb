{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copyright 2019 The TensorFlow Authors.\n",
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_Qp173_NbG5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "import IPython.display as display\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(img):\n",
    "    img = 255*(img + 1.0)/2.0\n",
    "    return tf.cast(img, tf.uint8)\n",
    "\n",
    "def show(img):\n",
    "    display.display(PIL.Image.fromarray(np.array(img)))\n",
    "\n",
    "def save(img,name):\n",
    "    PIL.Image.fromarray(np.array(img)).save(name+\".png\",\"PNG\")\n",
    "\n",
    "original_img = tf.cast(np.random.randint(50, size=(512, 512, 3)), tf.uint8)\n",
    "#original_img = np.array(PIL.Image.open('noise04.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlLi48GKNbGy"
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08KB502ONbGt"
   },
   "outputs": [],
   "source": [
    "names = ['mixed3', 'mixed5','mixed7','mixed9']\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "\n",
    "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MhfSweXXiuq"
   },
   "outputs": [],
   "source": [
    "def calc_loss(img, model):\n",
    "    img_batch = tf.expand_dims(img, axis=0)\n",
    "    layer_activations = model(img_batch)\n",
    "    if len(layer_activations) == 1:\n",
    "        layer_activations = [layer_activations]\n",
    "\n",
    "    losses = []\n",
    "    for act in layer_activations:\n",
    "        loss = tf.math.reduce_mean(act)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return  tf.reduce_sum(losses)#-tf.image.total_variation(img)/100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGgLHk7o80ac"
   },
   "outputs": [],
   "source": [
    "def random_roll(img, maxroll):\n",
    "    shift = tf.random.uniform(shape=[2], minval=-maxroll, maxval=maxroll, dtype=tf.int32)\n",
    "    shift_down, shift_right = shift[0],shift[1] \n",
    "    img_rolled = tf.roll(tf.roll(img, shift_right, axis=1), shift_down, axis=0)\n",
    "    return shift_down, shift_right, img_rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x__TZ0uqNbGm"
   },
   "outputs": [],
   "source": [
    "class TiledGradients(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(input_signature=(tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "                                  tf.TensorSpec(shape=[], dtype=tf.int32),  ))\n",
    "\n",
    "    def __call__(self, img, tile_size=512,  ):      \n",
    "        shift_down, shift_right, img_rolled = random_roll(img, tile_size)\n",
    "        gradients = tf.zeros_like(img_rolled)\n",
    "        \n",
    "        xs = tf.range(0, img_rolled.shape[0], tile_size)[:-1]\n",
    "        if not tf.cast(len(xs), bool):\n",
    "            xs = tf.constant([0])\n",
    "        ys = tf.range(0, img_rolled.shape[1], tile_size)[:-1]\n",
    "        if not tf.cast(len(ys), bool):\n",
    "            ys = tf.constant([0])\n",
    "\n",
    "        for x in xs:\n",
    "            for y in ys:\n",
    "                with tf.GradientTape() as tape:    \n",
    "                    tape.watch(img_rolled) \n",
    "                    img_tile = img_rolled[x:x+tile_size, y:y+tile_size]\n",
    "                    loss = calc_loss(img_tile, self.model)\n",
    "                gradients = gradients + tape.gradient(loss, img_rolled)\n",
    "            gradients = tf.roll(tf.roll(gradients, -shift_right, axis=1), -shift_down, axis=0)\n",
    "            gradients /= tf.math.reduce_std(gradients) + 1e-5 \n",
    "        return gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vcq4GubA2e5J"
   },
   "outputs": [],
   "source": [
    "get_gradients = TiledGradients(dream_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gA-15DM4NbGk"
   },
   "outputs": [],
   "source": [
    "def run_deep_dream_with_octaves(img, steps_per_octave=50, step_size=0.01, \n",
    "                                octaves=range(-3,3), octave_scale=1.5):\n",
    "    base_shape = tf.shape(img)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "\n",
    "    initial_shape = img.shape[:-1]\n",
    "    img = tf.image.resize(img, initial_shape)\n",
    "    resized_img = img\n",
    "    for octave in octaves:\n",
    "        new_size = tf.cast(tf.convert_to_tensor(base_shape[:-1]), tf.float32)*(octave_scale**octave)\n",
    "        for step in range(steps_per_octave):\n",
    "            resized_img = tf.image.resize(img, tf.cast(new_size, tf.int32))\n",
    "            gradients = get_gradients(resized_img)\n",
    "            resized_img = resized_img+gradients*step_size\n",
    "            resized_img = tf.clip_by_value(resized_img, -1, 1)\n",
    "                \n",
    "            gradients =  tf.image.resize(gradients, initial_shape)\n",
    "            img = img + gradients*step_size\n",
    "            img = tf.clip_by_value(img, -1, 1)\n",
    "  \n",
    "    result = deprocess(img)\n",
    "    return result\n",
    "\n",
    "def run_deep_dream_with_octaves_resize(img, steps_per_octave=50, step_size=0.01, \n",
    "                                octaves=range(-3,3), octave_scale=1.5):\n",
    "    base_shape = tf.shape(img)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "\n",
    "    initial_shape = img.shape[:-1]\n",
    "    for octave in octaves:\n",
    "        new_size = tf.cast(tf.convert_to_tensor(base_shape[:-1]), tf.float32)*(octave_scale**octave)\n",
    "        for step in range(steps_per_octave):\n",
    "            img = tf.image.resize(img, tf.cast(new_size, tf.int32))\n",
    "           \n",
    "            gradients = get_gradients(img)\n",
    "            img = img+gradients*step_size\n",
    "            img = tf.clip_by_value(img, -1, 1)\n",
    "    \n",
    "    result = deprocess(img)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7PbRLV74RrU"
   },
   "outputs": [],
   "source": [
    "img = run_deep_dream_with_octaves_resize(img=original_img, steps_per_octave=50, step_size=0.01,octaves=range(-4,3), octave_scale=1.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deepdream.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
